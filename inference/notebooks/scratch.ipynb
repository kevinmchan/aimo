{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f75394-43c0-4c19-a64f-ad8cee12c003",
   "metadata": {},
   "source": [
    "# Messing around with LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53ed8fd-5d65-4e0b-b652-cdc7500dc914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set logging level\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3050dcef-ef8f-4e36-92fc-7316db6e0129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read environment variables from project .env file\n",
    "# Assumes that there is an openai api key stored in a .env file \n",
    "# under the variable name `OPENAI_API_KEY`\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e11789-3c16-465e-a3d6-220c44ef81cc",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2915ecbd-c488-4702-90a3-17a652ad20c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"hf://datasets/HuggingFaceH4/MATH-500/test.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e503315-8b82-4682-81e8-c77869a0dfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4617ee-c71f-407f-904f-d2dd1d78670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dataset on integer answers\n",
    "def is_int_like(inp) -> bool:\n",
    "    try:\n",
    "        int(inp)\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "df_int_ans = df[df[\"answer\"].map(is_int_like)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf1eebb-17cb-47d5-8202-6d4358932915",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_int_ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c59207c-f8f9-4df8-b70d-c537ec97b9d2",
   "metadata": {},
   "source": [
    "## Instantiate OpenAI model client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4a0322-cab2-41d8-a933-40c1a8d4ae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b8e275-6710-460b-bcfd-d9048eabade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI()\n",
    "model = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc4e70f-ba13-4416-8581-d448ce4df0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful math assistant. Answer any questions using step by step reasoning. Enclose final answers to questions in \\\\boxed{}\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2+2?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db6095b-f9e3-4081-8486-ed288ede33e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai_client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de056f4-394a-4259-9035-df1e7fd0710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_content = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed466706-b774-47af-9133-b6df472647f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c373d6-6581-4615-a76c-5862bafcefd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(client, problem):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f532eecb-aa4e-4a49-8487-c1747b6699e9",
   "metadata": {},
   "source": [
    "## Instantiate vllm (local) model client\n",
    "\n",
    "Serve model using:\n",
    "```bash\n",
    "vllm serve <model> \\\n",
    "    --dtype <dtype> \\\n",
    "    --trust-remote-code \\\n",
    "    --quantization <quantization> \\\n",
    "    --load-format <load-format> \\\n",
    "    --tensor-parallel-size <gpu-count> \\\n",
    "    --api-key <key> \\\n",
    "    --served-model localmodel \\\n",
    "    --max-model-len <max-model-len>\n",
    "```\n",
    "\n",
    "Example:\n",
    "```bash\n",
    "vllm serve deepseek-ai/DeepSeek-R1-Distill-Qwen-14B \\\n",
    "    --dtype bfloat16 \\\n",
    "    --trust-remote-code \\\n",
    "    --quantization bitsandbytes \\\n",
    "    --load-format bitsandbytes \\\n",
    "    --tensor-parallel-size 1 \\\n",
    "    --api-key token-abc123 \\\n",
    "    --served-model localmodel \\\n",
    "    --max-model-len 4096\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbd43a4-ba42-45b8-a10f-4625111d1760",
   "metadata": {},
   "outputs": [],
   "source": [
    "vllm_client = OpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"token-abc123\",\n",
    ")\n",
    "model = \"localmodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed23c6f-86b8-4fc9-a9e6-f439ef9ba0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = vllm_client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    max_tokens=2048,\n",
    "    top_p=0.95\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06978c07-fe72-47e8-b94e-42d51cb6d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_content = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d103bd-ebda-4130-8394-6550185f374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9f89ab-6c2d-446d-9533-92e3d35cfc02",
   "metadata": {},
   "source": [
    "## Extract answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1924d133-0662-46a3-be27-1b9b5c0b5016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_boxed(text: str) -> str | None:\n",
    "    answer_pattern = r'boxed{(.*?)}'\n",
    "    matches = re.findall(answer_pattern, text)\n",
    "    if not matches:\n",
    "        return\n",
    "    return matches[-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb890e49-330c-4a98-959a-aebc3e6601fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_boxed(response_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
